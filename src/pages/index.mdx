---
layout: ../layouts/Layout.astro
title: Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: favicon.svg
thumbnail: screenshot.png
---
import WarningWithCheckbox from '../components/Warnings.astro';
import Application from '../components/Application.astro';
import Motivation from '../components/Motivation.astro';
import Layout from "../layouts/Layout.astro";
import GetInvolved from "../components/involved.astro";
import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import poster from "../assets/poster.PNG";
import outside from "../assets/outside.mp4";
import method_comparison from "../assets/method_comparison.png";
import Splat from "../components/Splat.tsx"

import CodeBlock from "../components/CodeBlock.astro";
export const components = {pre: CodeBlock}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Peiyan Zhang",
      url: "https://peiyance.github.io/",
      institution: "Hong Kong University of Science and Technology",
    },
    {
      name: "Haibo Jin",
      url: "https://haibojin001.github.io/",
      institution: "University of Illinois at Urbana-Champaign",
    },
    {
      name: "Leyang Hu",
      url: "https://openreview.net/profile?id=~Leyang_Hu1",
      institution: "Brown University",
    },
    {
      name: "Xinnuo Li",
      url: "https://openreview.net/profile?id=~Xinnuo_Li2",
      institution: "University of Michigan - Ann Arbor",
    },
    {
      name: "Liying Kang",
      url: "https://openreview.net/profile?id=~Liying_Kang1",
      institution: "Hong Kong Polytechnic University",
    },
    {
      name: "Man Luo",
      url: "https://luomancs.github.io/",
      institution: "Intel Lab",
    },
    {
      name: "Yangqiu Song",
      url: "https://www.cse.ust.hk/~yqsong/",
      institution: "Hong Kong University of Science and Technology",
    },
    {
      name: "Haohan Wang",
      url: "https://haohanwang.github.io/",
      institution: "University of Illinois at Urbana-Champaign",
      notes: ["â€ "],
    },
  ]}
  notes={[
    {
      symbol: "â€ ",
      text: "Corresponding Author",
    },
  ]}
  links={[
    {
      name: "Paper",
      url: "https://arxiv.org/pdf/2412.03092",
      icon: "fa-solid:file-pdf",
    },
    {
      name: "Code",
      url: "https://github.com/Peiyance/REVOLVE",
      icon: "mdi:github",
    },
    {
      name: "arXiv",
      url: "https://arxiv.org/abs/2412.03092",
      icon: "academicons:arxiv",
    },
  ]}
  />

 {/*<Video source={outside} />*/}



<HighlightedSection>

## Abstract
<p class="flex flex-col gap-4 items-center pt-12 pb-6 w-full *:px-6 *:max-w-full">Abstract</p>
<br/>

Recent advancements in large language models (LLMs) have significantly enhanced the ability of LLM-based systems to perform complex tasks through natural language processing and tool interaction. However, optimizing these LLM-based systems for specific tasks remains challenging, often requiring manual interventions like prompt engineering and hyperparameter tuning. Existing automatic optimization methods, such as textual feedback-based techniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to using immediate derivatives in traditional numerical gradient descent. However, relying solely on such feedback can be limited when the adjustments made in response to this feedback are either too small or fluctuate irregularly, potentially slowing down or even stalling the optimization process.  To overcome these challenges, more adaptive methods are needed, especially in situations where the systemâ€™s response is evolving slowly or unpredictably. In this paper, we introduce **REVOLVE**, an optimization method that tracks how **R**esponses **EVOLVE** across iterations in LLM systems. By focusing on the evolution of responses over time, REVOLVE enables more stable and effective optimization by making thoughtful, progressive adjustments at each step. We evaluate the effectiveness of REVOLVE across three tasks: prompt optimization, solution optimization, and code optimization. Experimental results demonstrate that REVOLVE outperforms competitive baselines, achieving a **7.8%** improvement in prompt optimization, a **20.72%** gain in solution refinement, and a **29.17%** increase in code optimization. Additionally, REVOLVE converges in fewer iterations, resulting in significant computational savings. These advantages highlight its adaptability and efficiency, positioning REVOLVE as a valuable tool for optimizing LLM-based systems and accelerating the development of next-generation AI technologies.

</HighlightedSection>



## Motivation
 - ðŸŽ¯ REVOLVE is an optimization framework that enhances the stability and efficiency of AI system optimization by tracking the evolution of model responses across iterations. Building on textual feedback from LLMs, Revolve simulates higher-order optimization effects, ensuring that adjustments are guided not only by immediate feedback but also by the modelâ€™s performance trajectory, leading to faster and more stable optimization without relying on traditional derivative-based methods.
- ðŸŽ¯ REVOLVE offers an intuitive API, built upon the foundation of [TextGrad](https://github.com/zou-group/textgrad), that allows users to define custom optimization tasks and loss functions. This makes it an adaptable and effective tool for optimizing LLM-based systems across a range of applications, including prompt optimization, solution refinement, and code optimization.

<Figure
    caption=""
  >
    <Image source={method_comparison} altText="The illustrative comparison between REVOLVE and first-order optimization methods." />
</Figure>

## Applications
Below are examples showcasing the effectiveness and versatility of REVOLVE in diverse applications.
  <Application />


## Related Links

This project has been inspired by numerous excellent works! Below is a non-exhaustive list of key references:
- ðŸ“– [DSPy](https://github.com/stanfordnlp/dspy) A pioneering framework for leveraging LMs in diverse applications, which significantly influenced our approach.
- ðŸ“– [ProTeGi](https://github.com/microsoft/LMOps/tree/main/prompt_optimization): The term 'Textual Gradients' was inspired by ProTeGiâ€™s prompt optimization methods.
- ðŸ“– [Reflexion](https://github.com/noahshinn/reflexion): A self-reflection framework that demonstrated the power of text-based reflection in optimization.
- ðŸ“– [TextGrad](https://github.com/zou-group/textgrad): Laying the foundation for implementing LLM-based "gradient" pipelines, TextGrad offers a streamlined interface for text optimization tasks, which directly contributed to the development of our approach.


## Get Involved
We're excited to have you join our community! Whether you're interested in collaborating, sharing insights, or exploring innovative solutions in trustworthy machine learning, there are many ways to get involved:

<GetInvolved />

## BibTeX citation
If you find our work useful, please consider citing us:
```bibtex
@misc{zhang2024revolveoptimizingaisystems,
      title={Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization}, 
      author={Peiyan Zhang and Haibo Jin and Leyang Hu and Xinnuo Li and Liying Kang and Man Luo and Yangqiu Song and Haohan Wang},
      year={2024},
      eprint={2412.03092},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03092}, 
}
```
