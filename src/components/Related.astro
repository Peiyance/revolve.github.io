---
---

<style>
  /* Global style for the component */
  .related-link {
    color: hsl(204, 86%, 53%) !important;
    text-decoration: none;
  }

  .related-link:hover {
    text-decoration: underline;
  }

  /* Styling for the list */
  .related-links-list {
    font-family: 'Noto Sans', sans-serif;
  }

  .related-links-list li {
    margin-bottom: 8px;
  }
</style>

<p style="font-family: 'Noto Sans', sans-serif;">
  This project has been inspired by numerous excellent works! Below is a non-exhaustive list of key references:
</p>

<ul class="related-links-list">
  <li>
    ðŸ”° <a href="https://github.com/stanfordnlp/dspy" class="related-link">
      DSPy
    </a> 
    and 
    <a href="https://github.com/google-deepmind/opro" class="related-link">
      OPRO
    </a>: Pioneering frameworks for leveraging LMs in diverse applications, which significantly influenced our approach.
  </li>
  <li>
    ðŸ”° <a href="https://github.com/microsoft/LMOps/tree/main/prompt_optimization" class="related-link">
      ProTeGi
    </a>: The term 'Textual Gradients' was inspired by ProTeGiâ€™s prompt optimization methods.
  </li>
  <li>
    ðŸ”° <a href="https://github.com/noahshinn/reflexion" class="related-link">
      Reflexion
    </a>: A self-reflection framework that demonstrated the power of text-based reflection in optimization.
  </li>
  <li>
    ðŸ”° <a href="https://github.com/zou-group/textgrad" class="related-link">
      TextGrad
    </a>: Laying the foundation for implementing LLM-based "gradient" pipelines, TextGrad offers a streamlined interface for text optimization tasks, which directly contributed to the development of our approach.
  </li>
</ul>
